# LLM Assisted Reflection to Wellness-NLP-Pipeline-Weak-Labeling-with-GPT-and-BERTweet-Fine-Tuning
I led and architected the below project end-to-end as a reflection-based NLP system for Uplifty‚Äôs Human Growth Index, designing the methodology, building the dataset labeling pipeline, implementing preprocessing and model training workflows, and coordinating a 5-member team to support large-scale data generation, experimentation, and model evaluation.

INTRODUCTION

This project originates from Uplifty, a platform built with a simple mission: help people improve their everyday lives through consistent habits, meaningful goals, real-world experiences, and authentic human connection. Rather than encouraging passive scrolling or superficial online engagement, Uplifty promotes action‚Äîfollowing routines, completing challenges, participating in events, and supporting others. To measure this progress holistically, Uplifty introduced the Human Growth Index (HGI), a score that reflects how consistently users take constructive steps toward personal, social, and emotional well-being.
While many behaviors can be tracked directly‚Äîsuch as goal completion or event participation‚Äînot all aspects of growth leave clear digital footprints. Important dimensions like mental health, spirituality, learning, compassion, or life transitions often show up only in personal thoughts and experiences. This insight led to the idea of Reflections, short daily journal entries that allow users to express their day in their own words. These reflections capture the human side of growth that traditional activity tracking cannot measure.
 
ABSTRACT
This project builds an end-to-end AI system that converts users‚Äô daily journal-style reflections into measurable wellness insights. Using GPT-based weak labeling to automatically generate training data and a BERTweet transformer model fine-tuned with PyTorch, the pipeline processes informal, emotion-rich text (including emojis and conversational language) and performs multi-label classification across multiple wellness dimensions such as mental, physical, financial, and social health. The model then combines these predictions using a simple weighted scoring method to compute an overall Human Growth Index, turning unstructured personal narratives into clear, quantitative metrics that can be tracked over time. In short, it transforms free-text reflections into actionable well-being signals through a scalable, production-ready NLP pipeline.To demonstrate the system in a practical and user-friendly way, a lightweight web application was also developed to showcase the functionality through an interactive interface.


# ‚öôÔ∏è Technical Methodology

## 1Ô∏è‚É£ Data Acquisition & Dataset Construction
### 1.1 Problem ‚Äî No Labeled Reflection Dataset
  To train a supervised multi-label wellness classifier, we require text paired with wellness categories. However, no public dataset directly maps diary-style reflections to structured wellness dimensions such as mental, physical, spiritual, financial, or social health. This created a fundamental bottleneck: we had raw text but no reliable labels for training or evaluation.
  
### 1.2 Automated Label Generation using LLMs
So inorder to overcome the bottleneck one idea is  to do Manual annotation for 100,000+ entries which was infeasible. Instead, we used  GPT APIs to automatically label each record.
Each text was passed through a strict JSON-schema prompt to assign:
| Dimension                          | Label Range |
| ---------------------------------- | ----------- |
| Physical wellness                  | -1 / 0 / 1  |
| Intellectual wellness              | 0 / 1       |
| Occupational wellness              | -1 / 0 / 1  |
| Financial wellness                 | -1 / 0 / 1  |
| Social interaction wellness        | -1 / 0 / 1  |
| Spiritual wellness                 | 0 / 1       |
| Mental wellness                    | -1 / 0 / 1  |
| Compassion / contribution wellness | 0 / 1       |
| Family & caregiving                | -1 / 0 / 1  |
| Leisure & travel                   | 0 / 1       |
| Life events & transitions          | 0 / 1       |
| Neutral                            | 0 / 1       |




### 1.3 Base Text Source Selection
After exploring multiple options (Reddit posts, online diary blogs, scraped personal reflections), we selected Kaggle‚Äôs HappyDB dataset, which contains over 100,000 short, clean, diary-style text entries describing everyday experiences and emotions.
Reasons for choosing HappyDB:
‚Ä¢	Large scale (100k+ records)
‚Ä¢	High quality and cleaned text
‚Ä¢	Natural first-person reflections
‚Ä¢	Covers diverse life experiences aligned with wellness dimensions
This dataset provided strong semantic coverage for all 11 growth dimensions while being easier to standardize compared to noisy scraped sources.
Approximately 50,000 labeled samples were generated in one day, forming the initial training corpus.

### 1.4 Label Reliability Improvements (Planned)
Since LLM-generated labels can be inconsistent, we planned:
‚Ä¢	Confidence filtering
‚Ä¢	Revalidation using stronger models
‚Ä¢	Prompt optimization
‚Ä¢	Strict schema enforcement
These steps improve label stability and reduce noise.
 
## 2. Data Cleaning & Processing
### 2.1 Custom Stopword Strategy
We customized standard stopword removal to preserve context that is critical in reflection-style text. Instead of blindly removing common words, we retained linguistic cues that indicate speaker perspective, negation, and situational meaning, since these directly affect wellness interpretation.
Key adjustments include:
‚Ä¢	Preserve negations: not, no, never
‚Ä¢	Preserve pronouns: I, me, my, we, they
‚Ä¢	Preserve context markers: this, that, here, when, how
‚Ä¢	Maintain first-person focus for accurate ‚Äúuser-state‚Äù detection
‚Ä¢	Avoid loss of semantic polarity caused by removing negation terms
This ensures correct differentiation between personal experiences (e.g., ‚ÄúI am not feeling well‚Äù) and external references (e.g., ‚ÄúMy friend is not feeling well‚Äù), improving classification reliability

### 2.2 Emoji Processing
Reflections often contain emojis that carry strong emotional and contextual meaning (e.g., happiness, stress, frustration, love). Instead of treating emojis as noise or removing them during cleaning, we treat them as semantic features that directly contribute to model predictions.
We implemented a custom emoji-aware preprocessing pipeline that detects emojis using Unicode ranges and converts them into textual tokens compatible with the language model.
Processing steps include:
Detect emojis using a dedicated Unicode regex pattern
Convert each emoji to its text alias using emoji.demojize()
Example: üòÇ ‚Üí face_with_tears_of_joy
Keep only aliases that exist in the BERTweet vocabulary (avoid [UNK] tokens)
Collapse consecutive repeated emojis into a single token to prevent noise
Example: üòÇüòÇüòÇ ‚Üí face_with_tears_of_joy
Preserve emojis directly in the token stream alongside words so they are embedded like regular tokens
This approach allows emotional signals such as üòä, üòî, ‚ù§Ô∏è, or üòÇ to be represented explicitly in the embedding space, enabling the model to better capture sentiment, mood, and affective context present in short personal reflections.

*******************************INCLUDE THE CODE CELL PICTURE HERE **********************
### 2.3 Language Model Selection for Text Style
We selected Meta AI‚Äôs BERTweet due to its specialization in informal, short-form, and social-language text similar to diary reflections. Compared to standard BERT models, BERTweet better captures conversational tone and emoji semantics.
Reasons for selection:
‚Ä¢	Pretrained on social media language
‚Ä¢	Handles slang, abbreviations, and informal grammar
‚Ä¢	Native emoji vocabulary support
‚Ä¢	Strong performance on short, personal texts
‚Ä¢	More aligned with reflection-style inputs than vanilla BERT
This makes it well-suited for modeling real-world user reflections.
 
## 3. Training Procedures Explored
To determine the most practical and effective way to use Meta AI‚Äôs BERTweet for wellness reflection classification, we evaluated three progressively advanced training strategies‚Äîstarting from a simple frozen baseline, moving to selective fine-tuning, and finally exploring parameter-efficient methods‚Äîto balance accuracy, stability, and computational cost.
### 3.1 Approach 1 ‚Äî Frozen Embeddings (Feature Extraction Only)
In the first approach, we used Meta AI‚Äôs BERTweet only as a text encoder. We did not train or modify the transformer at all. Instead, the model simply converted each reflection into numerical embeddings, and those embeddings were passed to traditional machine learning models for classification.
This setup was mainly used to create a quick and reliable baseline. Since no deep learning weights were updated, training was very fast and required very little compute. It also made debugging easier. However, because the language model stayed frozen, it could not learn the specific style or vocabulary of wellness reflections, which limited the final accuracy.
Key points:
‚Ä¢	Transformer completely frozen
‚Ä¢	Use embeddings with Logistic Regression / Random Forest / LightGBM
‚Ä¢	Very fast and low cost
‚Ä¢	Stable and simple
‚Ä¢	Lower accuracy due to no domain learning
 
### 3.2 Approach 2 ‚Äî Partial Fine-Tuning (Selected Strategy)
In the second approach, we allowed the model to learn a little. Instead of training all 135 million parameters, we only unfroze the top two or three layers of the transformer and kept the rest frozen. This let the model adapt to wellness-related language while still keeping training efficient.
This turned out to be the best balance. The model learned the domain better, improved accuracy, and still trained quickly. It also converged faster, usually within about nine epochs. Because it offered strong performance without high compute costs, we chose this as the final production method.
Key points:
‚Ä¢	Only top layers trained (~2M parameters)
‚Ä¢	Learns wellness-specific language
‚Ä¢	Faster training than full fine-tuning
‚Ä¢	Better accuracy than frozen setup
‚Ä¢	Selected as the final approach
 
### 3.3 Approach 3 ‚Äî Parameter-Efficient Fine-Tuning (Exploratory)
In the third approach, we tested more advanced techniques like LoRA and other PEFT methods. These methods add small trainable components (adapters) instead of updating the whole model. The idea is to get good performance while using very little memory and compute.
Although these methods are promising, they were harder to implement and integrate into our pipeline. Because of these practical challenges, we did not fully adopt them yet. We plan to revisit them later as future improvements.
Key points:
‚Ä¢	Train only small adapter modules
‚Ä¢	Very low memory and compute usage
‚Ä¢	More complex to implement
‚Ä¢	Kept for future experimentation
 
#### Final Takeaway (Simple View)
You can think of the three approaches like this:
‚Ä¢	Frozen ‚Üí fastest but less accurate
‚Ä¢	Partial fine-tuning ‚Üí best balance of speed and accuracy
‚Ä¢	PEFT ‚Üí most efficient in theory but harder to set up
Because of this trade-off, partial fine-tuning gave the most practical and reliable results for the system.
 
## 3.4 Hyperparameters Used
Parameter	Value
Epochs	9
Learning Rate	2e-5 (small for stability)
Batch Size	16‚Äì32
Max Sequence Length	128‚Äì256
Layers Unfrozen	Top 3
Loss	Multi-label BCEWithLogits
Negative labels (-1) were converted into auxiliary ‚Äúnot_category‚Äù features for compatibility with training.
 
## 4. Model Saving & Exporting
After training, models were packaged for deployment:
Saved Components
1.	pytorch_model.bin ‚Äì model weights
2.	Tokenizer ‚Äì ensures consistent preprocessing
3.	config.json ‚Äì metadata (labels, thresholds, input size)
This guarantees inference-time reproducibility.
 
## 5. Metrics
Evaluation Results
Precision:
Recall:
F1 Score:
(Values to be added after final evaluation)
 
## 6. Website Creation & Deployment
### 6.1 Backend Integration
After training, the model was converted from an offline experiment into a deployable backend service. All inference steps were centralized inside a single app.py pipeline (which is used to deploy the model as a website) so that the same preprocessing, tokenization, and prediction logic used during training are reused during deployment. This keeps behavior consistent and prevents training‚Äìserving mismatches across development and production.
When the server starts, it loads the saved model artifacts into memory once for efficiency. The backend then works as a simple processing layer: it accepts reflection text, cleans and tokenizes it, runs the model for inference, and returns probability scores for each wellness dimension. Keeping everything in one modular pipeline makes the system easier to maintain, debug, and scale.
For reliable and reproducible deployment, the components are saved as separate standard files:
‚Ä¢	pytorch_model.bin ‚Üí trained model weights
‚Ä¢	Tokenizer files (via save_pretrained()) ‚Üí consistent preprocessing during inference
‚Ä¢	config.json ‚Üí metadata (model info, labels, thresholds, max input length)
This artifact-based structure ensures the backend can reliably reload the exact same model configuration and simplifies versioning and future updates.
 
## 7. Scoring Mechanism
After classification, predicted categories are combined using a weight-based scoring framework to compute the Human Wellness Score which is later used in Human Growth Index calculation.
Approach:
‚Ä¢	Weighted sum of wellness dimensions
‚Ä¢	Similar to credit scoring or player rating systems
‚Ä¢	Currently manually tuned
‚Ä¢	Future work: learned or adaptive weights
# EXAMPLE
Considering the following reflection and the probabilities predicted by the model:
‚ÄúI went for a short run in the morning and completed my work tasks on time, but I felt mentally drained, worried about my finances, skipped social plans, and struggled to focus in the evening.
Predicted probabilities
‚Ä¢	Physical ‚Üí 0.75
‚Ä¢	Occupational/Productivity ‚Üí 0.70
‚Ä¢	Mental stress (non-physical) ‚Üí 0.60
‚Ä¢	Financial stress (non-physical) ‚Üí 0.55
‚Ä¢	Social withdrawal (non-physical) ‚Üí 0.50
Example weights
‚Ä¢	Physical = +0.35
‚Ä¢	Occupational = +0.25
‚Ä¢	Mental = ‚àí0.20
‚Ä¢	Financial = ‚àí0.10
‚Ä¢	Social = ‚àí0.10
Wellness Score calculation
Score = (0.75√ó0.35) + (0.70√ó0.25) ‚àí (0.60√ó0.20) ‚àí (0.55√ó0.10) ‚àí (0.50√ó0.10)
Score ‚âà 0.21
This way, positive behaviors increase the score while non-physical stress factors reduce it, giving a balanced and realistic Human Wellness Score.

